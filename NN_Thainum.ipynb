{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pycaret.classification import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tune_sklearn import TuneSearchCV,TuneGridSearchCV\n",
    "\n",
    "\n",
    "from data_prepare_func import convert_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def detect_and_crop_handwriting(image):\n",
    "    _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    height, width = image.shape[:2]\n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "    max_offset = -1\n",
    "    max_offset_contour = None\n",
    "\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] == 0:\n",
    "            cX = 0\n",
    "            cY = 0\n",
    "        else:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "        offset = np.sqrt((center_x - cX) ** 2 + (center_y - cY) ** 2)\n",
    "\n",
    "        if offset > max_offset:\n",
    "            max_offset = offset\n",
    "            max_offset_contour = contour\n",
    "\n",
    "    if max_offset_contour is not None:\n",
    "        x, y, w, h = cv2.boundingRect(max_offset_contour)\n",
    "\n",
    "        aspect_ratio = float(w) / h\n",
    "\n",
    "        if aspect_ratio > 1:\n",
    "            y_padding = int((w - h) / 2)\n",
    "            x_padding = 0\n",
    "        else:\n",
    "            x_padding = int((h - w) / 2)\n",
    "            y_padding = 0\n",
    "\n",
    "        x -= x_padding\n",
    "        w += 2 * x_padding\n",
    "        y -= y_padding\n",
    "        h += 2 * y_padding\n",
    "\n",
    "        x = max(x, 0)\n",
    "        w = min(w, width)\n",
    "        y = max(y, 0)\n",
    "        h = min(h, height)\n",
    "\n",
    "        cropped_image = image[y:y + h, x:x + w]\n",
    "\n",
    "        # resized_image = cv2.resize(cropped_image, (300, 300))\n",
    "\n",
    "        # resized_gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # resized_gray = resized_gray.reshape((28, 28, 1))\n",
    "\n",
    "        return cropped_image\n",
    "\n",
    "    else:\n",
    "        print('No handwriting detected in the image.')\n",
    "        return None\n",
    "\n",
    "def convert_to_array(data_path,size):\n",
    "    folders = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    X, y = [], []\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "        images = os.listdir(folder_path)\n",
    "        for image_name in images:\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.dilate(image, kernel, iterations=1)\n",
    "            image = detect_and_crop_handwriting(image)\n",
    "            image = cv2.resize(image, (size, size))  # Resize the image to 28x28 pixels\n",
    "            X.append(image.flatten())  # Flatten the image and add it to the feature matrix\n",
    "            y.append(int(folder))  # Add the corresponding label\n",
    "\n",
    "    X_data = np.array(X)\n",
    "    y_data = np.array(y)\n",
    "    return X_data,y_data\n",
    "\n",
    "\n",
    "# data = pickle.load(open(\"thainumber_{}.pkl\".format(size), \"rb\"))\n",
    "# X = data['X']\n",
    "# Y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = convert_to_array(\"data_train/\",size=28)\n",
    "x_test,y_test = convert_to_array('data_test/',size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62124166,  0.37952436, -0.31049217, ..., -0.05845332,\n",
       "        -0.05008589, -0.03133927],\n",
       "       [ 0.37952436,  1.01841765, -0.10105859, ..., -0.01027454,\n",
       "        -0.00817466,  0.00324883],\n",
       "       [-0.31049217, -0.10105859,  1.27935792, ...,  0.002136  ,\n",
       "        -0.00642512, -0.00390119],\n",
       "       ...,\n",
       "       [-0.05845332, -0.01027454,  0.002136  , ...,  0.26859247,\n",
       "         0.04267642,  0.04830039],\n",
       "       [-0.05008589, -0.00817466, -0.00642512, ...,  0.04267642,\n",
       "         0.22346822,  0.05440044],\n",
       "       [-0.03133927,  0.00324883, -0.00390119, ...,  0.04830039,\n",
       "         0.05440044,  0.18291335]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.cov(x_train ,x_test )\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setup(x_train, target = y_train, session_id = 10,fold=5,preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>0.8371</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>0.8142</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.8353</td>\n",
       "      <td>0.8292</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8134</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>0.8355</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.8346</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.7944</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.7852</td>\n",
       "      <td>0.7776</td>\n",
       "      <td>0.7537</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.6388</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.6145</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>0.6145</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.5728</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.5097</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.4159</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "et                 Extra Trees Classifier    0.8321  0.9816  0.8321  0.8371   \n",
       "lightgbm  Light Gradient Boosting Machine    0.8313  0.9820  0.8313  0.8353   \n",
       "rf               Random Forest Classifier    0.8305  0.9781  0.8305  0.8355   \n",
       "lr                    Logistic Regression    0.8272  0.9812  0.8272  0.8346   \n",
       "svm                   SVM - Linear Kernel    0.8150  0.0000  0.8150  0.8230   \n",
       "gbc          Gradient Boosting Classifier    0.7783  0.9731  0.7783  0.7852   \n",
       "knn                K Neighbors Classifier    0.7229  0.9403  0.7229  0.7791   \n",
       "nb                            Naive Bayes    0.6610  0.8963  0.6610  0.6829   \n",
       "dt               Decision Tree Classifier    0.6145  0.7859  0.6145  0.6296   \n",
       "lda          Linear Discriminant Analysis    0.4980  0.8489  0.4980  0.5097   \n",
       "ridge                    Ridge Classifier    0.4727  0.0000  0.4727  0.4952   \n",
       "ada                  Ada Boost Classifier    0.2257  0.6372  0.2257  0.1916   \n",
       "qda       Quadratic Discriminant Analysis    0.1524  0.5293  0.1524  0.3366   \n",
       "dummy                    Dummy Classifier    0.1011  0.5000  0.1011  0.0102   \n",
       "\n",
       "              F1   Kappa     MCC  TT (Sec)  \n",
       "et        0.8313  0.8135  0.8142     0.084  \n",
       "lightgbm  0.8292  0.8125  0.8134     0.210  \n",
       "rf        0.8279  0.8116  0.8127     0.084  \n",
       "lr        0.8271  0.8080  0.8089     0.544  \n",
       "svm       0.8151  0.7944  0.7954     0.060  \n",
       "gbc       0.7776  0.7537  0.7545     0.104  \n",
       "knn       0.7164  0.6921  0.7005     0.178  \n",
       "nb        0.6388  0.6232  0.6312     0.062  \n",
       "dt        0.6171  0.5717  0.5728     0.190  \n",
       "lda       0.4976  0.4422  0.4432     0.058  \n",
       "ridge     0.4741  0.4141  0.4159     0.042  \n",
       "ada       0.1478  0.1389  0.1687     0.066  \n",
       "qda       0.1091  0.0586  0.0663     0.066  \n",
       "dummy     0.0186  0.0000  0.0000     0.062  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 10,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       173\n",
      "           1       1.00      1.00      1.00       175\n",
      "           2       1.00      1.00      1.00       177\n",
      "           3       1.00      1.00      1.00       178\n",
      "           4       1.00      1.00      1.00       174\n",
      "           5       1.00      1.00      1.00       175\n",
      "           6       1.00      1.00      1.00       174\n",
      "           7       1.00      1.00      1.00       175\n",
      "           8       1.00      1.00      1.00       174\n",
      "           9       1.00      1.00      1.00       178\n",
      "\n",
      "    accuracy                           1.00      1753\n",
      "   macro avg       1.00      1.00      1.00      1753\n",
      "weighted avg       1.00      1.00      1.00      1753\n",
      "\n",
      "Test Score:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        91\n",
      "           1       0.94      0.66      0.77        90\n",
      "           2       0.81      0.61      0.70        90\n",
      "           3       0.51      0.81      0.63        91\n",
      "           4       0.66      0.43      0.52        90\n",
      "           5       0.54      0.44      0.48        89\n",
      "           6       0.51      0.71      0.60        90\n",
      "           7       0.62      0.59      0.60        90\n",
      "           8       0.48      0.33      0.39        89\n",
      "           9       0.47      0.67      0.55        94\n",
      "\n",
      "    accuracy                           0.61       904\n",
      "   macro avg       0.64      0.61      0.61       904\n",
      "weighted avg       0.64      0.61      0.61       904\n",
      "\n",
      "AVG F1-Score Train: 1.0\n",
      "Accuracy_nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        91\n",
      "           1       0.94      0.66      0.77        90\n",
      "           2       0.81      0.61      0.70        90\n",
      "           3       0.51      0.81      0.63        91\n",
      "           4       0.66      0.43      0.52        90\n",
      "           5       0.54      0.44      0.48        89\n",
      "           6       0.51      0.71      0.60        90\n",
      "           7       0.62      0.59      0.60        90\n",
      "           8       0.48      0.33      0.39        89\n",
      "           9       0.47      0.67      0.55        94\n",
      "\n",
      "    accuracy                           0.61       904\n",
      "   macro avg       0.64      0.61      0.61       904\n",
      "weighted avg       0.64      0.61      0.61       904\n",
      "\n",
      "Confusion Matrix:\n",
      "[[75  4  0  4  0  0  4  3  0  1]\n",
      " [11 59  0  3  0  0 12  5  0  0]\n",
      " [ 1  0 55  1  2  3 16  2  3  7]\n",
      " [ 0  0  1 74  0  1  5  4  0  6]\n",
      " [ 0  0  2 11 39  9  4  4  8 13]\n",
      " [ 1  0  2 12  7 39  6  1  5 16]\n",
      " [ 0  0  2 15  0  4 64  3  1  1]\n",
      " [ 3  0  1  3  2  4  1 53 11 12]\n",
      " [ 0  0  5 12  4  6 11  7 29 15]\n",
      " [ 0  0  0 10  5  6  2  4  4 63]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the neural network model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', random_state=42 , alpha=0.01)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "train_yhat = model.predict(x_train)\n",
    "train_score = classification_report(y_train, train_yhat)\n",
    "print(\"Train Score:\\n\", train_score)\n",
    "\n",
    "# Test Score\n",
    "test_yhat = model.predict(x_test)\n",
    "test_score = classification_report(y_test, test_yhat)\n",
    "print(\"Test Score:\\n\", test_score)\n",
    "\n",
    "# F1-Score\n",
    "train_f1 = f1_score(y_train, train_yhat, average='weighted')\n",
    "print(f\"AVG F1-Score Train: {train_f1}\")\n",
    "\n",
    "#predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy_nn\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>23:12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Loading Dependencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Compiling Library</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    \n",
       "                                                                    \n",
       "Initiated  . . . . . . . . . . . . . . . . . .              23:12:13\n",
       "Status     . . . . . . . . . . . . . . . . . .  Loading Dependencies\n",
       "Estimator  . . . . . . . . . . . . . . . . . .     Compiling Library"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9e9b5_row5_col0, #T_9e9b5_row5_col1, #T_9e9b5_row5_col2, #T_9e9b5_row5_col3, #T_9e9b5_row5_col4, #T_9e9b5_row5_col5, #T_9e9b5_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9e9b5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9e9b5_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_9e9b5_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_9e9b5_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_9e9b5_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_9e9b5_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_9e9b5_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_9e9b5_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9b5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9e9b5_row0_col0\" class=\"data row0 col0\" >0.8496</td>\n",
       "      <td id=\"T_9e9b5_row0_col1\" class=\"data row0 col1\" >0.9881</td>\n",
       "      <td id=\"T_9e9b5_row0_col2\" class=\"data row0 col2\" >0.8496</td>\n",
       "      <td id=\"T_9e9b5_row0_col3\" class=\"data row0 col3\" >0.8475</td>\n",
       "      <td id=\"T_9e9b5_row0_col4\" class=\"data row0 col4\" >0.8469</td>\n",
       "      <td id=\"T_9e9b5_row0_col5\" class=\"data row0 col5\" >0.8329</td>\n",
       "      <td id=\"T_9e9b5_row0_col6\" class=\"data row0 col6\" >0.8332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9b5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9e9b5_row1_col0\" class=\"data row1 col0\" >0.8577</td>\n",
       "      <td id=\"T_9e9b5_row1_col1\" class=\"data row1 col1\" >0.9846</td>\n",
       "      <td id=\"T_9e9b5_row1_col2\" class=\"data row1 col2\" >0.8577</td>\n",
       "      <td id=\"T_9e9b5_row1_col3\" class=\"data row1 col3\" >0.8619</td>\n",
       "      <td id=\"T_9e9b5_row1_col4\" class=\"data row1 col4\" >0.8591</td>\n",
       "      <td id=\"T_9e9b5_row1_col5\" class=\"data row1 col5\" >0.8419</td>\n",
       "      <td id=\"T_9e9b5_row1_col6\" class=\"data row1 col6\" >0.8421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9b5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9e9b5_row2_col0\" class=\"data row2 col0\" >0.8327</td>\n",
       "      <td id=\"T_9e9b5_row2_col1\" class=\"data row2 col1\" >0.9795</td>\n",
       "      <td id=\"T_9e9b5_row2_col2\" class=\"data row2 col2\" >0.8327</td>\n",
       "      <td id=\"T_9e9b5_row2_col3\" class=\"data row2 col3\" >0.8468</td>\n",
       "      <td id=\"T_9e9b5_row2_col4\" class=\"data row2 col4\" >0.8302</td>\n",
       "      <td id=\"T_9e9b5_row2_col5\" class=\"data row2 col5\" >0.8141</td>\n",
       "      <td id=\"T_9e9b5_row2_col6\" class=\"data row2 col6\" >0.8161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9b5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9e9b5_row3_col0\" class=\"data row3 col0\" >0.8367</td>\n",
       "      <td id=\"T_9e9b5_row3_col1\" class=\"data row3 col1\" >0.9779</td>\n",
       "      <td id=\"T_9e9b5_row3_col2\" class=\"data row3 col2\" >0.8367</td>\n",
       "      <td id=\"T_9e9b5_row3_col3\" class=\"data row3 col3\" >0.8427</td>\n",
       "      <td id=\"T_9e9b5_row3_col4\" class=\"data row3 col4\" >0.8336</td>\n",
       "      <td id=\"T_9e9b5_row3_col5\" class=\"data row3 col5\" >0.8186</td>\n",
       "      <td id=\"T_9e9b5_row3_col6\" class=\"data row3 col6\" >0.8199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9b5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9e9b5_row4_col0\" class=\"data row4 col0\" >0.8612</td>\n",
       "      <td id=\"T_9e9b5_row4_col1\" class=\"data row4 col1\" >0.9835</td>\n",
       "      <td id=\"T_9e9b5_row4_col2\" class=\"data row4 col2\" >0.8612</td>\n",
       "      <td id=\"T_9e9b5_row4_col3\" class=\"data row4 col3\" >0.8645</td>\n",
       "      <td id=\"T_9e9b5_row4_col4\" class=\"data row4 col4\" >0.8602</td>\n",
       "      <td id=\"T_9e9b5_row4_col5\" class=\"data row4 col5\" >0.8458</td>\n",
       "      <td id=\"T_9e9b5_row4_col6\" class=\"data row4 col6\" >0.8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9b5_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_9e9b5_row5_col0\" class=\"data row5 col0\" >0.8476</td>\n",
       "      <td id=\"T_9e9b5_row5_col1\" class=\"data row5 col1\" >0.9827</td>\n",
       "      <td id=\"T_9e9b5_row5_col2\" class=\"data row5 col2\" >0.8476</td>\n",
       "      <td id=\"T_9e9b5_row5_col3\" class=\"data row5 col3\" >0.8527</td>\n",
       "      <td id=\"T_9e9b5_row5_col4\" class=\"data row5 col4\" >0.8460</td>\n",
       "      <td id=\"T_9e9b5_row5_col5\" class=\"data row5 col5\" >0.8306</td>\n",
       "      <td id=\"T_9e9b5_row5_col6\" class=\"data row5 col6\" >0.8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9b5_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_9e9b5_row6_col0\" class=\"data row6 col0\" >0.0113</td>\n",
       "      <td id=\"T_9e9b5_row6_col1\" class=\"data row6 col1\" >0.0036</td>\n",
       "      <td id=\"T_9e9b5_row6_col2\" class=\"data row6 col2\" >0.0113</td>\n",
       "      <td id=\"T_9e9b5_row6_col3\" class=\"data row6 col3\" >0.0088</td>\n",
       "      <td id=\"T_9e9b5_row6_col4\" class=\"data row6 col4\" >0.0125</td>\n",
       "      <td id=\"T_9e9b5_row6_col5\" class=\"data row6 col5\" >0.0125</td>\n",
       "      <td id=\"T_9e9b5_row6_col6\" class=\"data row6 col6\" >0.0119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x175f9bd60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a499556dd64049a46635c47d332cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a neural network model\n",
    "nn_model = create_model('mlp')\n",
    "\n",
    "# Tune the neural network model\n",
    "tuned_nn = tune_model(nn_model)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "evaluate_model(tuned_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ietemmi/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6095132743362832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tune_sklearn import TuneSearchCV\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#x_train, x_test, y_train, y_test = train_test_split(y_train, test_size=0.3, random_state=42,stratify=y_train)\n",
    "\n",
    "\n",
    "# parameter\n",
    "param_grid = {\n",
    "   'hidden_layer_sizes': [(20,), (50,), (100,)],\n",
    "   'activation': ['relu', 'tanh'],\n",
    "   'solver': ['adam', 'sgd'],\n",
    "}\n",
    "\n",
    "# Create the scikit-learn model\n",
    "model = MLPClassifier(random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning using TuneSearchCV\n",
    "tuned = GridSearchCV(model, param_grid,cv=5,n_jobs=-1,scoring='accuracy')\n",
    "\n",
    "# Fit the tuned model on the training data\n",
    "tuned.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the tuned model on the testing data\n",
    "test_score = tuned.score(x_test, y_test)\n",
    "print(\"Test Score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'hidden_layer_sizes': (200,), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863106227106227"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
