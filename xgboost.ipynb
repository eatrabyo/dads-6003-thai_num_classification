{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold, RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pycaret.classification import *\n",
    "#import xgboost as xgb\n",
    "from xgboost import XGBClassifier,XGBRFClassifier\n",
    "from tune_sklearn import TuneSearchCV,TuneGridSearchCV\n",
    "\n",
    "from data_prepare_func import convert_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = convert_to_array(\"data_train/\",size=28)\n",
    "x_test,y_test = convert_to_array('data_test/',size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.append(x_train,x_test,axis=0)\n",
    "y = np.append(y_train,y_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgbrf = XGBRFClassifier()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[185   0   0   0   0   0   0   0   0   0]\n",
      " [  0 185   0   0   0   0   0   0   0   0]\n",
      " [  0   0 187   0   0   0   0   0   0   0]\n",
      " [  0   0   0 187   0   0   1   0   0   0]\n",
      " [  0   0   0   1 183   0   1   0   0   0]\n",
      " [  0   0   0   1   0 184   0   0   0   0]\n",
      " [  0   0   0   0   0   0 185   0   0   0]\n",
      " [  0   0   0   0   0   0   0 185   0   0]\n",
      " [  0   0   0   0   0   0   1   0 183   0]\n",
      " [  0   0   0   0   1   0   0   0   0 189]]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(objective=\"multi:softprob\", random_state=59)\n",
    "xgb.fit(x_train,y_train)\n",
    "\n",
    "y_pred = xgb.predict(x_train)\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'use_label_encoder': None,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': 59,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.8125     0.83522727 0.85795455 0.90285714 0.86857143 0.86857143\n",
      " 0.82285714 0.86857143 0.87428571 0.94285714]\n",
      "Mean: 0.8654253246753246\n",
      "Standard Deviation: 0.036174442458010554\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100)\n",
    "scores = cross_val_score(xgb, x_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       173\n",
      "           1       1.00      1.00      1.00       175\n",
      "           2       1.00      1.00      1.00       177\n",
      "           3       1.00      1.00      1.00       178\n",
      "           4       1.00      1.00      1.00       174\n",
      "           5       1.00      1.00      1.00       175\n",
      "           6       1.00      1.00      1.00       174\n",
      "           7       1.00      1.00      1.00       175\n",
      "           8       1.00      1.00      1.00       174\n",
      "           9       1.00      1.00      1.00       178\n",
      "\n",
      "    accuracy                           1.00      1753\n",
      "   macro avg       1.00      1.00      1.00      1753\n",
      "weighted avg       1.00      1.00      1.00      1753\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.57        91\n",
      "           1       0.60      0.64      0.62        90\n",
      "           2       0.34      0.79      0.48        90\n",
      "           3       0.77      0.71      0.74        91\n",
      "           4       0.38      0.50      0.43        90\n",
      "           5       0.80      0.22      0.35        89\n",
      "           6       0.67      0.04      0.08        90\n",
      "           7       0.27      0.73      0.39        90\n",
      "           8       0.38      0.19      0.25        89\n",
      "           9       0.79      0.12      0.20        94\n",
      "\n",
      "    accuracy                           0.44       904\n",
      "   macro avg       0.57      0.44      0.41       904\n",
      "weighted avg       0.57      0.44      0.41       904\n",
      "\n",
      "Accuracy Score Train: 1.0\n",
      "Accuracy Score Test: 0.4424778761061947\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(x_train,y_train)\n",
    "\n",
    "train_yhat = xgb.predict(x_train)\n",
    "train_accuracy = accuracy_score(train_yhat,y_train)\n",
    "\n",
    "test_yhat = xgb.predict(x_test)\n",
    "test_accuracy = accuracy_score(test_yhat,y_test)\n",
    "\n",
    "print('Train Score\\n',classification_report(y_train,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test,test_yhat))\n",
    "print(f\"Accuracy Score Train: {train_accuracy}\\nAccuracy Score Test: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth' : [ i for i in range(1,11,1)],\n",
    "    # 'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "    # 'gamma': [0, 0.5, 1],\n",
    "    # #'reg_alpha': [0, 0.5, 1],\n",
    "    # #'reg_lambda': [0.5, 1, 5],\n",
    "    # 'subsample' : [0.5,0.7,0.9],\n",
    "    # 'colsample_bytree': [0.5,0.7,0.9],\n",
    "    # 'tree_method': ['approx','hist','gpu_hist']\n",
    "}\n",
    "tune = GridSearchCV(XGBRFClassifier(),cv=5,param_grid=parameters,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "param_grid = { \n",
    "    # Percentage of columns to be randomly samples for each tree.\n",
    "    \"colsample_bytree\": [ 0.3, 0.5 , 0.8 ],\n",
    "    # reg_alpha provides l1 regularization to the weight, higher values result in more conservative models\n",
    "    \"reg_alpha\": [0, 0.5, 1, 5],\n",
    "    # reg_lambda provides l2 regularization to the zweight, higher values result in more conservative models\n",
    "    \"reg_lambda\": [0, 0.5, 1, 5]\n",
    "    }\n",
    "# Set up score\n",
    "scoring = ['recall']\n",
    "# Set up the k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "tune.fit(x_train, y_train)\n",
    "print(tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'max_depth' : [ i for i in range(1,11,1)],\n",
    "    'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "    # 'gamma': [0, 0.5, 1],\n",
    "    # #'reg_alpha': [0, 0.5, 1],\n",
    "    # #'reg_lambda': [0.5, 1, 5],\n",
    "    # 'subsample' : [0.5,0.7,0.9],\n",
    "    # 'colsample_bytree': [0.5,0.7,0.9],\n",
    "    # 'tree_method': ['approx','hist','gpu_hist']\n",
    "}\n",
    "tune = GridSearchCV(XGBRFClassifier(),cv=5,param_grid=parameters,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "tune.fit(x_train, y_train)\n",
    "print(tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'max_depth' : [ i for i in range(1,11,1)],\n",
    "    #'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 5],\n",
    "    # 'subsample' : [0.5,0.7,0.9],\n",
    "    # 'colsample_bytree': [0.5,0.7,0.9],\n",
    "    # 'tree_method': ['approx','hist','gpu_hist']\n",
    "}\n",
    "tune = GridSearchCV(XGBRFClassifier(),cv=5,param_grid=parameters,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 0.5}\n"
     ]
    }
   ],
   "source": [
    "tune.fit(x_train, y_train)\n",
    "print(tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'max_depth' : [ i for i in range(1,11,1)],\n",
    "    #'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "    # 'gamma': [0, 0.5, 1],\n",
    "    # 'reg_alpha': [0, 0.5, 1],\n",
    "    # 'reg_lambda': [0.5, 1, 5],\n",
    "    'subsample' : [0.5,0.7,0.9],\n",
    "    'colsample_bytree': [0.5,0.7,0.9],\n",
    "    # 'tree_method': ['approx','hist','gpu_hist']\n",
    "}\n",
    "tune = GridSearchCV(XGBRFClassifier(),cv=5,param_grid=parameters,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "tune.fit(x_train, y_train)\n",
    "print(tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'max_depth' : [ i for i in range(1,11,1)],\n",
    "    #'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "    # 'gamma': [0, 0.5, 1],\n",
    "    # 'reg_alpha': [0, 0.5, 1],\n",
    "    # 'reg_lambda': [0.5, 1, 5],\n",
    "    'subsample' : [0.5,0.7,0.9],\n",
    "    'colsample_bytree': [0.5,0.7,0.9],\n",
    "    'tree_method': ['approx','hist','gpu_hist']\n",
    "}\n",
    "tune = GridSearchCV(XGBRFClassifier(),cv=5,param_grid=parameters,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'subsample': 0.9, 'tree_method': 'hist'}\n"
     ]
    }
   ],
   "source": [
    "tune.fit(x_train, y_train)\n",
    "print(tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'max_depth' : [ i for i in range(1,11,1)],\n",
    "    'learning_rate': [0.01,0.05,0.1,0.2],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 5],\n",
    "    'subsample' : [0.5,0.7,0.9],\n",
    "    'colsample_bytree': [0.5,0.7,0.9],\n",
    "    'tree_method': ['approx','hist','gpu_hist'],\n",
    "    'colsample_bylevel' : [0.5,0.7,0.9],\n",
    "    'colsample_bynode' : [0.5,0.7,0.9],\n",
    "    'min_child_weight' : [0,3,6,9],\n",
    "    'eval_metric' : ['merror','merror']\n",
    "}\n",
    "tune = GridSearchCV(XGBRFClassifier(),cv=5,param_grid=parameters,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tune\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(tune\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tune.fit(x_train, y_train)\n",
    "print(tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=5,learning_rate=0.01,gamma=0,reg_alpha=0,reg_lambda=0.5,colsample_bytree=0.5,\n",
    "        subsample=0.7,tree_method='hist',n_estimators=140,eval_metric='merror',\n",
    "        colsample_bylevel=0.5,colsample_bynode=0.5)\n",
    "        # ,min_child_weight=20,max_leaf_nodes=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       185\n",
      "           1       1.00      0.97      0.98       185\n",
      "           2       0.99      0.94      0.96       187\n",
      "           3       0.97      0.98      0.97       188\n",
      "           4       0.95      0.84      0.89       185\n",
      "           5       0.93      0.92      0.92       185\n",
      "           6       0.96      0.95      0.95       185\n",
      "           7       0.92      0.89      0.90       185\n",
      "           8       0.91      0.89      0.90       184\n",
      "           9       0.77      0.98      0.86       190\n",
      "\n",
      "    accuracy                           0.93      1859\n",
      "   macro avg       0.94      0.93      0.93      1859\n",
      "weighted avg       0.94      0.93      0.93      1859\n",
      "\n",
      "Test Score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92        79\n",
      "           1       0.94      0.90      0.92        80\n",
      "           2       0.87      0.57      0.69        80\n",
      "           3       0.84      0.93      0.88        81\n",
      "           4       0.75      0.54      0.63        79\n",
      "           5       0.66      0.82      0.73        79\n",
      "           6       0.65      0.67      0.66        79\n",
      "           7       0.82      0.75      0.78        80\n",
      "           8       0.54      0.77      0.63        79\n",
      "           9       0.70      0.66      0.68        82\n",
      "\n",
      "    accuracy                           0.75       798\n",
      "   macro avg       0.77      0.75      0.75       798\n",
      "weighted avg       0.77      0.75      0.75       798\n",
      "\n",
      "Accuracy Score Train: 0.9322216245293168\n",
      "Accuracy Score Test: 0.7531328320802005\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(x_train,y_train)\n",
    "\n",
    "train_yhat = xgb.predict(x_train)\n",
    "train_accuracy = accuracy_score(train_yhat,y_train)\n",
    "\n",
    "test_yhat = xgb.predict(x_test)\n",
    "test_accuracy = accuracy_score(test_yhat,y_test)\n",
    "\n",
    "print('Train Score\\n',classification_report(y_train,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test,test_yhat))\n",
    "print(f\"Accuracy Score Train: {train_accuracy}\\nAccuracy Score Test: {test_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgbRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrf.fit(x_train,y_train)\n",
    "\n",
    "train_yhat = xgbrf.predict(x_train)\n",
    "train_accuracy = accuracy_score(train_yhat,y_train)\n",
    "\n",
    "test_yhat = xgbrf.predict(x_test)\n",
    "test_accuracy = accuracy_score(test_yhat,y_test)\n",
    "\n",
    "print('Train Score\\n',classification_report(y_train,train_yhat))\n",
    "print('Test Score\\n',classification_report(y_test,test_yhat))\n",
    "print(f\"Accuracy Score Train: {train_accuracy}\\nAccuracy Score Test: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01,0.05,0.1],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 5],\n",
    "    'base_score': [0.2, 0.5, 1]\n",
    "}\n",
    "tune = GridSearchCV(XGBRFClassifier(),cv=5,param_grid=parameters,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.fit(x_train, y_train)\n",
    "print(tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
